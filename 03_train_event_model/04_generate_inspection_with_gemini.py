# ==============================================================
# 04_generate_inspection_with_gemini_batch_v25.py
# Gemini 2.5 (v1 APIå¯¾å¿œ) ã‚’ä½¿ã£ãŸå¤§è¦æ¨¡æ¤œæŸ»ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆ
# ãƒãƒƒãƒå‡¦ç†ã§å®‰å®šå‹•ä½œã™ã‚‹æ”¹è‰¯ç‰ˆ
# ==============================================================

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time

# --------------------------------------------------------------
# Gemini åˆæœŸåŒ–ï¼ˆv1å¯¾å¿œï¼‰
# --------------------------------------------------------------
USE_GEMINI = True
try:
    import google.generativeai as genai

    genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

    # âœ… æœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼ˆç²¾åº¦é‡è¦–ï¼‰
    model = genai.GenerativeModel(model_name="models/gemini-2.5-pro")
    # model = genai.GenerativeModel(model_name="models/gemini-2.5-flash")  # é«˜é€ŸåŒ–ã—ãŸã„å ´åˆã¯ã“ã¡ã‚‰

    print("âœ… Geminiãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

except Exception as e:
    print("âš ï¸ GeminiåˆæœŸåŒ–ã«å¤±æ•—:", e)
    USE_GEMINI = False


# --------------------------------------------------------------
# ãƒ‘ã‚¹è¨­å®š
# --------------------------------------------------------------
BASE_DIR = "/content/synthetic-medical-text-pipeline"
INPUT_DIR = f"{BASE_DIR}/data/inputs"
OUTPUT_DIR = f"{INPUT_DIR}/outputs"
SCHEMA_PATH = f"{BASE_DIR}/data/schema/clinical_schema_v1.2.json"
VALUE_RANGES_PATH = f"{BASE_DIR}/data/schema/value_ranges.json"

os.makedirs(OUTPUT_DIR, exist_ok=True)


# --------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°
# --------------------------------------------------------------
def load_csv(name):
    """CSVã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦æƒ…å ±ã‚’è¡¨ç¤º"""
    path = f"{INPUT_DIR}/{name}"
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ {path} ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    df = pd.read_csv(path)
    print(f"âœ… {name}: {len(df):,}ä»¶, åˆ—: {list(df.columns)}")
    return df


# --------------------------------------------------------------
# å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# --------------------------------------------------------------
gender_df = load_csv("gender.csv")
disease_df = load_csv("disease.csv")
drug_df = load_csv("drug.csv")

# --------------------------------------------------------------
# ã‚¹ã‚­ãƒ¼ãƒãƒ»æ¤œæŸ»å€¤ç¯„å›²ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
# --------------------------------------------------------------
with open(SCHEMA_PATH, "r") as f:
    schema = json.load(f)
print(f"âœ… ã‚¹ã‚­ãƒ¼ãƒèª­è¾¼å®Œäº†: {SCHEMA_PATH}")

if os.path.exists(VALUE_RANGES_PATH):
    with open(VALUE_RANGES_PATH, "r") as f:
        value_ranges = json.load(f)
else:
    value_ranges = {}
    print("âš ï¸ value_ranges.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚AIç”Ÿæˆã§ä»£ç”¨ã—ã¾ã™ã€‚")

# --------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿çµ±åˆ
# --------------------------------------------------------------
merged = (
    disease_df.merge(drug_df, on="patient_id", how="inner", suffixes=("_dis", "_drug"))
    .merge(gender_df, on="patient_id", how="left")
)
merged["disease_date"] = pd.to_datetime(merged["disease_date"], errors="coerce")
merged["key_date"] = pd.to_datetime(merged["key_date"], errors="coerce")
print(f"ğŸ§© çµ±åˆãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(merged):,}")

# --------------------------------------------------------------
# Geminiã§æ¤œæŸ»å€™è£œã‚’æ¨å®š
# --------------------------------------------------------------
def get_tests_from_gemini(disease, drug, gender="ä¸æ˜"):
    """ç–¾æ‚£ãƒ»è–¬å‰¤ãƒ»æ€§åˆ¥ã‚’ã‚‚ã¨ã«é–¢é€£æ¤œæŸ»é …ç›®ã‚’Geminiã§æ¨å®š"""
    if not USE_GEMINI:
        return []

    try:
        prompt = f"""
ç–¾æ‚£ã€Œ{disease}ã€ã¨è–¬å‰¤ã€Œ{drug}ã€ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹{gender}ã®æ‚£è€…ã«å¯¾ã—ã¦ã€
è‡¨åºŠçš„ã«é–¢é€£æ€§ã®é«˜ã„æ¤œæŸ»é …ç›®ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
ä¸€èˆ¬çš„ãªæ¤œæŸ»åï¼ˆä¾‹ï¼šHbA1c, eGFR, AST, LDL-Cãªã©ï¼‰ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã¾ãŸã¯è‹±èªã®æ¤œæŸ»åã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§çŸ­ãè¿”ã—ã¦ãã ã•ã„ã€‚
"""
        response = model.generate_content([prompt])
        text = response.text.strip().replace("\n", "").replace("ã€", ",")
        tests = [t.strip() for t in text.split(",") if len(t.strip()) > 0]
        return tests[:5]
    except Exception as e:
        print("âš ï¸ Geminiå‘¼ã³å‡ºã—å¤±æ•—:", e)
        return []


# --------------------------------------------------------------
# æ¤œæŸ»å€¤ç”Ÿæˆï¼ˆæ—¢çŸ¥åˆ†å¸ƒ or AIæ¨å®šï¼‰
# --------------------------------------------------------------
def generate_value_and_unit(test_name):
    """æ¤œæŸ»é …ç›®åã«åŸºã¥ã„ã¦å€¤ã¨å˜ä½ã‚’ç”Ÿæˆ"""
    if test_name in value_ranges:
        info = value_ranges[test_name]
        mean = info.get("mean", 1)
        sd = info.get("sd", 0.1)
        unit = info.get("unit", "")
        value = np.round(np.random.normal(mean, sd), 2)
        return value, unit

    if USE_GEMINI:
        try:
            prompt = f"æ¤œæŸ»ã€Œ{test_name}ã€ã®æ­£å¸¸ç¯„å›²ã¨å˜ä½ã‚’ç°¡æ½”ã«1è¡Œã§æ•™ãˆã¦ãã ã•ã„ã€‚"
            res = model.generate_content([prompt])
            text = res.text.strip()
            unit = ""
            for token in ["mg/dL", "mmol/L", "U/L", "%", "mL/min", "g/dL"]:
                if token in text:
                    unit = token
            value = np.random.normal(1, 0.1)
            return round(float(abs(value)), 2), unit
        except:
            pass

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return np.round(np.random.uniform(0.1, 10.0), 2), ""


# --------------------------------------------------------------
# ãƒãƒƒãƒå‡¦ç†è¨­å®š
# --------------------------------------------------------------
BATCH_SIZE = 1000   # âš™ï¸ é©å®œèª¿æ•´ï¼ˆColabãªã‚‰ 500ã€œ2000 ä»¶ãŒå®‰å…¨ï¼‰
total = len(merged)
num_batches = (total // BATCH_SIZE) + 1

print(f"ğŸ“¦ ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {total:,} / ãƒãƒƒãƒæ•°: {num_batches:,}")

# --------------------------------------------------------------
# ãƒãƒƒãƒå‡¦ç†æœ¬ä½“
# --------------------------------------------------------------
for batch_idx, start in enumerate(range(0, total, BATCH_SIZE)):
    end = min(start + BATCH_SIZE, total)
    batch = merged.iloc[start:end]
    print(f"\nğŸš€ ãƒãƒƒãƒ {batch_idx+1}/{num_batches} å®Ÿè¡Œä¸­ ({start:,}ã€œ{end:,}) ä»¶...")

    out_rows = []

    for i, row in batch.iterrows():
        disease = row.get("disease_name", "")
        drug = row.get("drug_name", "")
        gender = row.get("gender", "ä¸æ˜")
        patient_id = row["patient_id"]

        tests = get_tests_from_gemini(disease, drug, gender)
        if len(tests) == 0:
            continue

        disease_date = row["disease_date"]
        if pd.isna(disease_date):
            continue

        inspection_date = disease_date + timedelta(days=int(np.random.choice([-1, 0, 1])))
        encounter_id = f"{patient_id}_{inspection_date.strftime('%Y%m%d')}"

        for test_name in tests:
            value, unit = generate_value_and_unit(test_name)
            out_rows.append({
                "patient_id": patient_id,
                "encounter_id": encounter_id,
                "disease_name": disease,
                "drug_name": drug,
                "inspection_name": test_name,
                "inspection_value": value,
                "unit": unit,
                "inspection_date": inspection_date.strftime("%Y-%m-%d"),
            })

    # ãƒãƒƒãƒçµæœã‚’ä¿å­˜
    out_df = pd.DataFrame(out_rows)
    now_str = datetime.now().strftime("%Y%m%d_%H%M")
    out_path = f"{OUTPUT_DIR}/inspection_generated_batch_{batch_idx+1}_{now_str}.csv"
    out_df.to_csv(out_path, index=False)
    print(f"ğŸ’¾ ãƒãƒƒãƒ {batch_idx+1} å‡ºåŠ›å®Œäº†: {out_path} / ä»¶æ•°: {len(out_df):,}")

    # âœ… APIè² è·ã‚’è»½æ¸›
    time.sleep(2)

print("ğŸ‰ ã™ã¹ã¦ã®ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
