# ==============================================================
# 04_generate_inspection_with_gemini_parallel_v25.py
# Gemini 2.5å¯¾å¿œï¼šä¸¦åˆ—å‡¦ç†ï¼‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®‰å®šç‰ˆ
# ==============================================================

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# --------------------------------------------------------------
# Gemini åˆæœŸåŒ–
# --------------------------------------------------------------
USE_GEMINI = True
try:
    import google.generativeai as genai
    genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
    model = genai.GenerativeModel(model_name="models/gemini-2.5-pro")
    print("âœ… Geminiãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
except Exception as e:
    print("âš ï¸ GeminiåˆæœŸåŒ–ã«å¤±æ•—:", e)
    USE_GEMINI = False


# --------------------------------------------------------------
# ãƒ‘ã‚¹è¨­å®š
# --------------------------------------------------------------
BASE_DIR = "/content/synthetic-medical-text-pipeline"
INPUT_DIR = f"{BASE_DIR}/data/inputs"
OUTPUT_DIR = f"{INPUT_DIR}/outputs"
SCHEMA_PATH = f"{BASE_DIR}/data/schema/clinical_schema_v1.2.json"
VALUE_RANGES_PATH = f"{BASE_DIR}/data/schema/value_ranges.json"
os.makedirs(OUTPUT_DIR, exist_ok=True)


# --------------------------------------------------------------
# CSVèª­ã¿è¾¼ã¿
# --------------------------------------------------------------
def load_csv(name):
    path = f"{INPUT_DIR}/{name}"
    df = pd.read_csv(path)
    print(f"âœ… {name}: {len(df):,}ä»¶, åˆ—: {list(df.columns)}")
    return df


gender_df = load_csv("gender.csv")
disease_df = load_csv("disease.csv")
drug_df = load_csv("drug.csv")


# --------------------------------------------------------------
# ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿
# --------------------------------------------------------------
with open(SCHEMA_PATH, "r") as f:
    schema = json.load(f)
print(f"âœ… ã‚¹ã‚­ãƒ¼ãƒèª­è¾¼å®Œäº†: {SCHEMA_PATH}")

if os.path.exists(VALUE_RANGES_PATH):
    with open(VALUE_RANGES_PATH, "r") as f:
        value_ranges = json.load(f)
else:
    print("âš ï¸ value_ranges.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚AIç”Ÿæˆã§ä»£ç”¨ã—ã¾ã™ã€‚")
    value_ranges = {}


# --------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿çµ±åˆ
# --------------------------------------------------------------
merged = (
    disease_df.merge(drug_df, on="patient_id", how="inner", suffixes=("_dis", "_drug"))
    .merge(gender_df, on="patient_id", how="left")
)
merged["disease_date"] = pd.to_datetime(merged["disease_date"], errors="coerce")
print(f"ğŸ§© çµ±åˆãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(merged):,}")

# âœ… å‹•ä½œç¢ºèªãƒ¢ãƒ¼ãƒ‰ï¼ˆã¾ãšã¯500ä»¶ã§è©¦ã™ï¼‰
merged = merged.sample(n=500, random_state=42)
print(f"ğŸ” ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œä»¶æ•°: {len(merged):,}")


# --------------------------------------------------------------
# Geminiå‘¼ã³å‡ºã—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
# --------------------------------------------------------------
@lru_cache(maxsize=None)
def get_tests_from_gemini_cached(disease, drug, gender="ä¸æ˜"):
    """ç–¾æ‚£Ã—è–¬å‰¤Ã—æ€§åˆ¥ã®çµ„åˆã›ã«å¯¾ã—ã¦1åº¦ã ã‘Geminiå‘¼ã³å‡ºã—"""
    if not USE_GEMINI:
        return tuple()

    try:
        prompt = f"""
ç–¾æ‚£ã€Œ{disease}ã€ã¨è–¬å‰¤ã€Œ{drug}ã€ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹{gender}ã®æ‚£è€…ã«å¯¾ã—ã¦ã€
è‡¨åºŠçš„ã«é–¢é€£æ€§ã®é«˜ã„æ¤œæŸ»é …ç›®ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã¾ãŸã¯è‹±èªã®æ¤œæŸ»åã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§çŸ­ãè¿”ã—ã¦ãã ã•ã„ã€‚
"""
        response = model.generate_content([prompt])
        text = response.text.strip().replace("\n", "").replace("ã€", ",")
        tests = [t.strip() for t in text.split(",") if len(t.strip()) > 0]
        return tuple(tests[:5])
    except Exception as e:
        print("âš ï¸ Geminiå‘¼ã³å‡ºã—å¤±æ•—:", e)
        return tuple()


# --------------------------------------------------------------
# æ¤œæŸ»å€¤ç”Ÿæˆ
# --------------------------------------------------------------
def generate_value_and_unit(test_name):
    if test_name in value_ranges:
        info = value_ranges[test_name]
        mean = info.get("mean", 1)
        sd = info.get("sd", 0.1)
        unit = info.get("unit", "")
        value = np.round(np.random.normal(mean, sd), 2)
        return value, unit

    return np.round(np.random.uniform(0.1, 10.0), 2), ""


# --------------------------------------------------------------
# ä¸¦åˆ—å‡¦ç†é–¢æ•°
# --------------------------------------------------------------
def process_row(row):
    disease = row.get("disease_name", "")
    drug = row.get("drug_name", "")
    gender = row.get("gender", "ä¸æ˜")
    patient_id = row["patient_id"]
    results = []

    tests = get_tests_from_gemini_cached(disease, drug, gender)
    if len(tests) == 0:
        return results

    disease_date = row["disease_date"]
    if pd.isna(disease_date):
        return results

    inspection_date = disease_date + timedelta(days=int(np.random.choice([-1, 0, 1])))
    encounter_id = f"{patient_id}_{inspection_date.strftime('%Y%m%d')}"

    for test_name in tests:
        value, unit = generate_value_and_unit(test_name)
        results.append({
            "patient_id": patient_id,
            "encounter_id": encounter_id,
            "disease_name": disease,
            "drug_name": drug,
            "inspection_name": test_name,
            "inspection_value": value,
            "unit": unit,
            "inspection_date": inspection_date.strftime("%Y-%m-%d"),
        })
    return results


# --------------------------------------------------------------
# ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
# --------------------------------------------------------------
out_rows = []
print("ğŸš€ ä¸¦åˆ—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [executor.submit(process_row, row) for _, row in merged.iterrows()]
    for f in as_completed(futures):
        try:
            out_rows.extend(f.result())
        except Exception as e:
            print("âš ï¸ ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ©ãƒ¼:", e)

# --------------------------------------------------------------
# å‡ºåŠ›
# --------------------------------------------------------------
out_df = pd.DataFrame(out_rows)
now_str = datetime.now().strftime("%Y%m%d_%H%M")
out_path = f"{OUTPUT_DIR}/inspection_generated_parallel_{now_str}.csv"
out_df.to_csv(out_path, index=False)

print(f"ğŸ’¾ å‡ºåŠ›å®Œäº†: {out_path}")
print(f"ğŸ§¾ ç”Ÿæˆä»¶æ•°: {len(out_df):,}")
print("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
