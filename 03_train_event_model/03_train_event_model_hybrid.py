# ==============================================
# ğŸ’ 03_colab_highprecision_plus_eval.py
#    - T4 GPUæœ€é©åŒ– + è£½å“åãƒ™ãƒ¼ã‚¹è–¬å‰¤å‡¦ç† + å“è³ªè©•ä¾¡ä»˜ãæœ€çµ‚ç‰ˆ
# ==============================================

import os
import re
import json
import argparse
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import torch
from sdv.single_table import CTGANSynthesizer
from sdv.metadata import SingleTableMetadata
from sdv.evaluation.single_table import evaluate_quality
from sdv.transformers import LabelEncoder, FrequencyEncoder, UnixTimestampEncoder

import warnings
warnings.filterwarnings("ignore")

# ----------------------------------------------
# å¼•æ•°è¨­å®š
# ----------------------------------------------
parser = argparse.ArgumentParser(description="CTGANå­¦ç¿’ï¼ˆColabå‘ã‘ãƒ»é«˜ç²¾åº¦ï¼‹è©•ä¾¡ä»˜ãï¼‰")
parser.add_argument("--epochs", type=int, default=50)
parser.add_argument("--base_dir", type=str, default=None)
parser.add_argument("--drop_emr_text", action="store_true")
parser.add_argument("--save_latest_alias", action="store_true")
parser.add_argument("--sample_n", type=int, default=0)
args = parser.parse_args() if __name__ == "__main__" else parser.parse_args("")

# ----------------------------------------------
# ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹è¨­å®š
# ----------------------------------------------
COLAB_BASE = "/content/synthetic-medical-text-pipeline"
BASE_DIR = Path(args.base_dir) if args.base_dir else (Path(COLAB_BASE) if Path(COLAB_BASE).exists() else Path(".."))
INPUT_DIR = BASE_DIR / "data" / "inputs"
OUTPUT_DIR = BASE_DIR / "data" / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
TS = datetime.now().strftime("%Y%m%d_%H%M%S")

# ----------------------------------------------
# GPU/CPUè‡ªå‹•åˆ¤å®š + OOMå¯¾ç­–
# ----------------------------------------------
if torch.cuda.is_available():
    try:
        torch.zeros((1024, 1024)).cuda()
        DEVICE = "cuda"
        print("ğŸŸ¢ GPU (T4) åˆ©ç”¨: CUDAæœ‰åŠ¹")
    except RuntimeError:
        DEVICE = "cpu"
        print("âš ï¸ GPUãƒ¡ãƒ¢ãƒªä¸è¶³ â†’ CPUã§å®Ÿè¡Œ")
else:
    DEVICE = "cpu"
    print("ğŸ’» CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")

# ----------------------------------------------
# CSVèª­è¾¼é–¢æ•°
# ----------------------------------------------
def load_csv(name: str):
    path = INPUT_DIR / f"{name}.csv"
    if not path.exists():
        raise FileNotFoundError(f"âŒ {path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    df = pd.read_csv(path)
    print(f"âœ… {name}.csv: {len(df):,}ä»¶")
    return df

def to_date(df, col):
    if col in df.columns:
        df["date"] = pd.to_datetime(df[col], errors="coerce")
    return df

# ----------------------------------------------
# ãƒ‡ãƒ¼ã‚¿èª­è¾¼
# ----------------------------------------------
print("ğŸ“¥ å®Ÿãƒ‡ãƒ¼ã‚¿èª­è¾¼ä¸­...")
gender_df = load_csv("gender")
disease_df = load_csv("disease")
inspection_df = load_csv("inspection")
drug_df = load_csv("drug")
emr_df = load_csv("emr")

if args.drop_emr_text and "emr_text" in emr_df.columns:
    emr_df = emr_df.drop(columns=["emr_text"])

# ----------------------------------------------
# æ—¥ä»˜å¤‰æ›
# ----------------------------------------------
disease_df = to_date(disease_df, "disease_date")
inspection_df = to_date(inspection_df, "inspection_date")
drug_df = to_date(drug_df, "drug_date" if "drug_date" in drug_df.columns else "key_date")
emr_df = to_date(emr_df, "emr_date")

# ----------------------------------------------
# gender æ­£è¦åŒ–
# ----------------------------------------------
if "gender" in gender_df.columns:
    gender_df["gender"] = gender_df["gender"].replace({"M":"ç”·æ€§","F":"å¥³æ€§","male":"ç”·æ€§","female":"å¥³æ€§"})

# ----------------------------------------------
# è£½å“åãƒ™ãƒ¼ã‚¹ã®è–¬å‰¤åå‡¦ç†
# ----------------------------------------------
def normalize_drug_name(name: str):
    if pd.isna(name):
        return name
    s = str(name)
    s = s.replace("ã€€", " ").replace("ï½ï½‡", "mg").replace("ï¼­ï¼§", "mg")
    s = re.sub(r"ï¼ˆ.*?ï¼‰|\(.*?\)", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

if "drug_name" in drug_df.columns:
    drug_df["drug_name"] = drug_df["drug_name"].map(normalize_drug_name)
    # ä½é »åº¦è–¬å‰¤ã‚’ã€Œãã®ä»–ã€ã«çµ±åˆ
    value_counts = drug_df["drug_name"].value_counts()
    rare_names = value_counts[value_counts < 10].index
    drug_df["drug_name"] = drug_df["drug_name"].replace(rare_names, "ãã®ä»–")
    # ä¸Šä½300è–¬å‰¤ã‚’ä¿æŒ
    top_drugs = drug_df["drug_name"].value_counts().head(300).index
    drug_df["drug_name"] = drug_df["drug_name"].apply(lambda x: x if x in top_drugs else "OTHER_DRUG")

# ----------------------------------------------
# ãƒ‡ãƒ¼ã‚¿çµ±åˆ
# ----------------------------------------------
print("ğŸ§© ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
for df, t in [(disease_df, "disease"), (inspection_df, "inspection"), (drug_df, "drug"), (emr_df, "emr")]:
    df["event_type"] = t

merged = pd.concat([disease_df, inspection_df, drug_df, emr_df], ignore_index=True)
merged = merged.merge(gender_df, on="patient_id", how="left")
merged = merged.sort_values(["patient_id", "date"]).reset_index(drop=True)

# ----------------------------------------------
# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
# ----------------------------------------------
train_cols = [c for c in ["patient_id","date","gender","disease_name","icd10_code","drug_name","inspection_name","inspection_value","department"] if c in merged.columns]
train = merged[train_cols].copy()
train["days_since_first"] = train.groupby("patient_id")["date"].transform(lambda x:(x-x.min()).dt.days)
train["month"] = train["date"].dt.month
if {"drug_name","department"}.issubset(train.columns):
    train["drug_name_department"] = train["drug_name"] + "_" + train["department"]
train = train.drop(columns=["patient_id","date"], errors="ignore")

# ----------------------------------------------
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å®šç¾© + ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼æŒ‡å®š
# ----------------------------------------------
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(train)
metadata.update_transformers({
    "gender": LabelEncoder(),
    "department": LabelEncoder(),
    "disease_name": FrequencyEncoder(),
    "drug_name": FrequencyEncoder(),
    "inspection_name": FrequencyEncoder(),
    "inspection_value": None,
    "days_since_first": None,
    "month": LabelEncoder(),
    "drug_name_department": FrequencyEncoder(),
})

meta_path = OUTPUT_DIR / f"ctgan_metadata_{TS}.json"
metadata.save_to_json(str(meta_path))
print(f"ğŸ’¾ ã‚¹ã‚­ãƒ¼ãƒä¿å­˜: {meta_path}")

# ----------------------------------------------
# CTGANå­¦ç¿’ (å®‰å®šåŒ– + batch_sizeæŒ‡å®š)
# ----------------------------------------------
print("ğŸš€ CTGANå­¦ç¿’é–‹å§‹...")
ctgan = CTGANSynthesizer(
    metadata,
    epochs=args.epochs,
    batch_size=500,
    cuda=(DEVICE == "cuda"),
)

try:
    ctgan.fit(train)
except RuntimeError as e:
    if "out of memory" in str(e).lower():
        print("âš ï¸ GPUãƒ¡ãƒ¢ãƒªä¸è¶³ â†’ CPUã§å†å­¦ç¿’")
        torch.cuda.empty_cache()
        ctgan = CTGANSynthesizer(metadata, epochs=args.epochs, batch_size=500, cuda=False)
        ctgan.fit(train)
    else:
        raise e

model_path = OUTPUT_DIR / f"ctgan_model_no_emrtext_{TS}.pkl"
ctgan.save(str(model_path))
print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")

# ----------------------------------------------
# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜
# ----------------------------------------------
train_path = OUTPUT_DIR / f"event_training_data_no_emrtext_{TS}.csv"
train.to_csv(train_path, index=False)
print(f"ğŸ’¾ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {train_path}")

if args.save_latest_alias:
    alias_path = OUTPUT_DIR / "event_training_data_no_emrtext_latest.csv"
    train.to_csv(alias_path, index=False)
    print(f"ğŸ”– æœ€æ–°ç‰ˆä¿å­˜: {alias_path}")

# ----------------------------------------------
# å“è³ªè©•ä¾¡
# ----------------------------------------------
print("ğŸ“ˆ åˆæˆãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ä¸­...")
try:
    synthetic_data = ctgan.sample(min(500, len(train)))
    quality = evaluate_quality(real_data=train.sample(min(1000, len(train))), synthetic_data=synthetic_data, metadata=metadata)
    report_path = OUTPUT_DIR / f"quality_report_{TS}.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(f"Quality Score: {quality.get_score():.3f}\n")
        f.write(str(quality.get_details()))
    print(f"ğŸ§¾ å“è³ªã‚¹ã‚³ã‚¢: {quality.get_score():.3f} â†’ è©³ç´°: {report_path}")
except Exception as e:
    print(f"âš ï¸ å“è³ªè©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: {e}")

# ----------------------------------------------
# ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆï¼ˆä»»æ„ï¼‰
# ----------------------------------------------
if args.sample_n>0:
    synth = ctgan.sample(args.sample_n)
    synth_out = OUTPUT_DIR / f"synthetic_events_{TS}.csv"
    synth.to_csv(synth_out, index=False)
    print(f"ğŸ§¬ ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ: {synth_out}")

print("\nğŸ‰ Step03 å®Œäº† â€” Colabé«˜ç²¾åº¦ï¼‹è©•ä¾¡ç‰ˆå®Ÿè¡Œæ¸ˆ\n")
