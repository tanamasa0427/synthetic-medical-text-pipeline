import os
import re
import torch
import pandas as pd
from sdv.single_table import CTGANSynthesizer
from sdv.metadata import SingleTableMetadata
from sdv.transformers import FrequencyEncoder, LabelEncoder, UnixTimestampEncoder
from sdv.evaluation.single_table import evaluate_quality

# ===============================================================
# 1ï¸âƒ£ åŸºæœ¬è¨­å®š
# ===============================================================
INPUT_PATH = '/kaggle/working/synthetic-medical-text-pipeline/data/inputs'
OUTPUT_PATH = '/kaggle/working/synthetic-medical-text-pipeline/data/outputs'
MODEL_NAME = 'ctgan_model_light'
EPOCHS = 50  # GPUã‚ã‚Šãªã®ã§é•·ã‚ã§ã‚‚OK
BATCH_SIZE = 500  # VRAMç¯€ç´„ã®ãŸã‚é©åº¦ã«è¨­å®š

# ===============================================================
# 2ï¸âƒ£ ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
# ===============================================================
device = "cuda" if torch.cuda.is_available() else "cpu"
if device == "cuda":
    print(f"ğŸ’¡ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda ({torch.cuda.get_device_name(0)})")
else:
    print("ğŸ’¡ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cpuï¼ˆGPUã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰")

# ===============================================================
# 3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿èª­è¾¼
# ===============================================================
def load_data():
    files = {
        'gender': 'gender.csv',
        'disease': 'disease.csv',
        'inspection': 'inspection.csv',
        'drug': 'drug.csv',
        'emr': 'emr.csv'
    }
    dfs = {}
    for key, file in files.items():
        path = os.path.join(INPUT_PATH, file)
        if os.path.exists(path):
            dfs[key] = pd.read_csv(path)
            print(f"âœ… Loaded {file}: {len(dfs[key])} rows")
        else:
            print(f"âš ï¸ File not found: {file}")
    return dfs

dfs = load_data()

# ===============================================================
# 4ï¸âƒ£ è£½å“åã®è»½ã„æ­£è¦åŒ–
# ===============================================================
def normalize_product_name(name: str) -> str:
    """è£½å“åã‚’è»½ãæ­£è¦åŒ–ï¼ˆæˆåˆ†å¤‰æ›ã¯è¡Œã‚ãªã„ï¼‰"""
    if pd.isna(name):
        return name
    name = name.strip().lower()
    name = name.translate(str.maketrans({'ã€€': ' ', 'ï¼ˆ': '(', 'ï¼‰': ')'}))
    name = re.sub(r'\s+', ' ', name)
    return name

if 'drug' in dfs:
    dfs['drug']['drug_name_norm'] = dfs['drug']['drug_name'].apply(normalize_product_name)

    # ===========================================================
    # Optionalæ”¹è‰¯â‘ ï¼šä½é »åº¦ã‚«ãƒ†ã‚´ãƒªã®çµ±åˆ
    # ===========================================================
    min_count = 10  # 10ä»¶æœªæº€ã®è£½å“ã‚’ã€Œãã®ä»–ã€ã«çµ±åˆ
    rare = dfs['drug']['drug_name_norm'].value_counts()[lambda x: x < min_count].index
    dfs['drug']['drug_name_norm'] = dfs['drug']['drug_name_norm'].replace(rare, 'ãã®ä»–')
    print(f"âœ… Reduced rare products to 'ãã®ä»–' ({len(rare)} rare items grouped)")

# ===============================================================
# 5ï¸âƒ£ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµ±åˆ
# ===============================================================
def merge_all(dfs):
    merged = []
    for name, df in dfs.items():
        df['event_type'] = name
        merged.append(df)
    df_all = pd.concat(merged, ignore_index=True)
    print(f"âœ… Total merged events: {len(df_all)}")
    return df_all

df_all = merge_all(dfs)

# ===============================================================
# 6ï¸âƒ£ Metadata å®šç¾© & ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒè¨­å®š
# ===============================================================
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(df_all)

metadata.update_transformers({
    # --- IDãƒ»åŸºæœ¬æƒ…å ± ---
    'hospital_id': None,
    'patient_id': None,
    'age': None,
    'gender': LabelEncoder(),

    # --- ç–¾æ‚£é–¢é€£ ---
    'disease_date': UnixTimestampEncoder(),
    'icd10_code': FrequencyEncoder(),
    'disease_name': FrequencyEncoder(),
    'is_suspected': LabelEncoder(),
    'admission_status': LabelEncoder(),
    'department': LabelEncoder(),

    # --- æ¤œæŸ» ---
    'inspection_date': UnixTimestampEncoder(),
    'inspection_name': FrequencyEncoder(),
    'inspection_value': None,
    'unit': LabelEncoder(),
    'æ¡å¦': LabelEncoder(),

    # --- è–¬å‰¤ ---
    'key_date': UnixTimestampEncoder(),
    'yj_code': LabelEncoder(),
    'drug_name_norm': FrequencyEncoder(),  # è£½å“åã‚’ç›´æ¥ä½¿ç”¨
    'amount': None,
    'days_count': None,
    'extracted_number': None,
    'daily_dosage': None,

    # --- EMR ---
    'emr_date': UnixTimestampEncoder(),
    'emr_type': LabelEncoder(),
    'emr_text': None
})

# ===============================================================
# 7ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ===============================================================
print("\nğŸ¤– CTGAN training start...")
synthesizer = CTGANSynthesizer(
    metadata,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    cuda=(device == "cuda")  # GPUè‡ªå‹•åˆ©ç”¨
)
synthesizer.fit(df_all)
print("âœ… CTGAN training complete.")

# ===============================================================
# 8ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
# ===============================================================
model_path = os.path.join(OUTPUT_PATH, f"{MODEL_NAME}.pkl")
synthesizer.save(model_path)
print(f"âœ… Model saved: {model_path}")

synthetic_data = synthesizer.sample(500)  # 500ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ
synthetic_path = os.path.join(OUTPUT_PATH, 'synthetic_sample.csv')
synthetic_data.to_csv(synthetic_path, index=False, encoding='utf-8')
print(f"ğŸ‰ Synthetic sample saved: {synthetic_path}")
print(synthetic_data.head())

# ===============================================================
# 9ï¸âƒ£ Optionalæ”¹è‰¯â‘¡ï¼šå“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
# ===============================================================
print("\nğŸ“Š Evaluating synthetic data quality...")
quality_report = evaluate_quality(
    real_data=df_all.sample(min(1000, len(df_all))),  # ä¸€éƒ¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ¯”è¼ƒ
    synthetic_data=synthetic_data,
    metadata=metadata
)
report_path = os.path.join(OUTPUT_PATH, 'quality_report.json')
quality_report.save(report_path)
print(f"âœ… Quality report saved: {report_path}")

summary = quality_report.get_summary()
print("\nğŸ” Quality Summary:")
print(summary)
