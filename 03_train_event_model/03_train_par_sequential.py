# ==========================================
# âœ… PARSynthesizer (æ™‚ç³»åˆ—) - SDV 0.18.0 å®‰å®šç‰ˆ
# å¯¾å¿œ: Python 3.10 / Kaggle ç’°å¢ƒ
# [æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ä¿®æ­£æ¸ˆã¿]
# ==========================================
import os
import pandas as pd
import numpy as np
import torch
from datetime import datetime
from tqdm import tqdm
from sdv.sequential import PARSynthesizer
from sdv.metadata import SingleTableMetadata

# ------------------------------------------
# âš™ï¸ ç’°å¢ƒè¨­å®š
# ------------------------------------------
ENVIRONMENT = "kaggle_working"

if ENVIRONMENT == "kaggle_working":
    BASE_DIR = "/kaggle/working/synthetic-medical-text-pipeline"
elif ENVIRONMENT == "colab":
    BASE_DIR = "/content/synthetic-medical-text-pipeline"
else:
    BASE_DIR = "./synthetic-medical-text-pipeline"

INPUT_DIR = os.path.join(BASE_DIR, "data/inputs")
OUTPUT_DIR = os.path.join(BASE_DIR, "data/outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
print(f"ğŸ“¦ SDV 0.18.0 PARSynthesizer ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹: {datetime.now():%Y-%m-%d %H:%M:%S}")

# ------------------------------------------
# 1. å®‰å…¨ãªCSVèª­è¾¼é–¢æ•°
# ------------------------------------------
def read_csv_safe(path):
    try:
        df = pd.read_csv(path)
        print(f"âœ… {os.path.basename(path)}: {len(df):,} ä»¶, åˆ—: {df.columns.tolist()}")
        return df
    except Exception as e:
        print(f"âš ï¸ {os.path.basename(path)} èª­è¾¼å¤±æ•—: {e}")
        return pd.DataFrame()

# ------------------------------------------
# 2. ãƒ‡ãƒ¼ã‚¿èª­è¾¼
# ------------------------------------------
gender_df = read_csv_safe(os.path.join(INPUT_DIR, "gender.csv"))
disease_df = read_csv_safe(os.path.join(INPUT_DIR, "disease.csv"))
inspection_df = read_csv_safe(os.path.join(INPUT_DIR, "inspection.csv"))
drug_df = read_csv_safe(os.path.join(INPUT_DIR, "drug.csv"))
emr_df = read_csv_safe(os.path.join(INPUT_DIR, "emr.csv"))

# ------------------------------------------
# 3. æ—¥ä»˜åˆ—ã¨ event_type åˆ—ã‚’çµ±ä¸€
# ------------------------------------------
def normalize(df, date_col, type_label):
    if df.empty:
        return df
    df = df.copy()
    if date_col in df.columns:
        df["date"] = pd.to_datetime(df[date_col], errors="coerce")
    else:
        df["date"] = pd.NaT
    df["event_type"] = type_label
    return df

disease_df = normalize(disease_df, "disease_date", "disease")
inspection_df = normalize(inspection_df, "inspection_date", "inspection")
drug_df = normalize(drug_df, "key_date", "drug")
emr_df = normalize(emr_df, "emr_date", "emr")

if "emr_text" in emr_df.columns:
    emr_df = emr_df.drop(columns=["emr_text"], errors="ignore")

# ------------------------------------------
# 4. çµåˆã¨å‰å‡¦ç†
# ------------------------------------------
merged_df = pd.concat([disease_df, inspection_df, drug_df, emr_df], ignore_index=True)

drop_cols = [
    "inspection_value", "drug_name", "icd10_code", "disease_name",
    "yj_code", "inspection_name", "amount", "days_count",
    "extracted_number", "daily_dosage"
]
merged_df = merged_df.drop(columns=[c for c in drop_cols if c in merged_df.columns], errors="ignore")

# æ—¥ä»˜NaTé™¤å¤–
merged_df["date"] = pd.to_datetime(merged_df["date"], errors="coerce")
before = len(merged_df)
merged_df = merged_df.dropna(subset=["date"])
print(f"ğŸ—“ï¸ NaTé™¤å¤–: {before - len(merged_df)} ä»¶å‰Šé™¤")

# ä¸è¦åˆ—é™¤å¤–
for c in ["disease_date", "inspection_date", "key_date", "emr_date"]:
    if c in merged_df.columns:
        merged_df = merged_df.drop(columns=[c], errors="ignore")

# å¹´é½¢åˆ—
if "age" in merged_df.columns:
    merged_df["age"] = pd.to_numeric(merged_df["age"], errors="coerce").fillna(0)

# ã‚«ãƒ†ã‚´ãƒªåˆ—æ­£è¦åŒ–
cat_cols = ['event_type', 'is_suspected', 'admission_status', 'department', 'unit', 'æ¡å¦', 'emr_type', 'hospital_id']
for col in cat_cols:
    if col in merged_df.columns:
        merged_df[col] = merged_df[col].fillna("Unknown").astype("category")

# patient_id ãƒã‚§ãƒƒã‚¯
if "patient_id" not in merged_df.columns:
    raise ValueError("âŒ å¿…é ˆåˆ— patient_id ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

merged_df["patient_id"] = merged_df["patient_id"].astype(str)

# ------------------------------------------
# 5. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ—ä½œæˆ
# ------------------------------------------
merged_df = merged_df.sort_values(by=["patient_id", "date"])
merged_df["sequence_order"] = merged_df.groupby("patient_id").cumcount() + 1

training_data = merged_df.reset_index(drop=True)
training_path = os.path.join(OUTPUT_DIR, f"event_training_data_sequential_{timestamp}.csv")
training_data.to_csv(training_path, index=False)
print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {training_path}")

# ------------------------------------------
# 6. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ (SDV 0.18.0 ä»•æ§˜)
# ------------------------------------------
print("ğŸ§  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­ (SDV 0.18.0 ä»•æ§˜)...")
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(training_data)

# Primary Key (ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ / ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚­ãƒ¼)
metadata.update_column("patient_id", sdtype="id")
metadata.set_primary_key("patient_id")

# Sequence Key (é †åºã‚­ãƒ¼)
metadata.update_column("sequence_order", sdtype="id")
metadata.set_sequence_key("sequence_order")

metadata.update_column("date", sdtype="datetime")

print("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº† (PK='patient_id', SK='sequence_order')")

# ------------------------------------------
# 7. PARSynthesizer å­¦ç¿’ (SDV 0.18.0 ä»•æ§˜)
# ------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ’¡ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

try:
    print("ğŸ¤– PARSynthesizer å­¦ç¿’é–‹å§‹ (EPOCHS=25, batch_size=500)")
    model = PARSynthesizer(metadata, cuda=(device == "cuda"))
    
    # SDV 0.18.0 ã§ã¯ .fit() ã« epochs ã¨ batch_size ã‚’æ¸¡ã™
    model.fit(training_data, epochs=25, batch_size=500)
    
    model_path = os.path.join(OUTPUT_DIR, f"par_model_light_{timestamp}.pkl")
    model.save(model_path)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")

except Exception as e:
    print(f"âŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

print("ğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
