import os
import re
import json
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import torch
import multiprocessing
import joblib

# =========================
# Windowså‘ã‘å®‰å®šåŒ–è¨­å®š
# =========================
if os.name == "nt":
    # Windowsã§ã¯ 'threading' ã¯éå¯¾å¿œãªã®ã§ 'spawn' ã‚’æ˜ç¤º
    multiprocessing.set_start_method("spawn", force=True)
    joblib.parallel_config(n_jobs=1)
    os.environ["LOKY_MAX_CPU_COUNT"] = "1"

from sdv.single_table import CTGANSynthesizer
from sdv.metadata import SingleTableMetadata

# =========================
# è¨­å®š
# =========================
DATA_DIR = Path("../data/inputs")
OUTPUT_DIR = Path("../data/outputs")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

EPOCHS = 25                  # CPUå®Ÿè¡Œã§ã‚‚ç¾å®Ÿçš„ãªå­¦ç¿’æ™‚é–“
SAMPLE_N = 20                # ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ä»¶æ•°
TOPK_DISEASE = 200           # ç–¾æ‚£ã‚«ãƒ†ã‚´ãƒªä¸Šä½
TOPK_DRUG = 200              # è–¬å‰¤ã‚«ãƒ†ã‚´ãƒªä¸Šä½
TOPK_INSPECTION = 80         # æ¤œæŸ»åã‚«ãƒ†ã‚´ãƒªä¸Šä½
TOPK_VALUE = 800             # æ¤œæŸ»å€¤ã‚«ãƒ†ã‚´ãƒªä¸Šä½
SAVE_PREFIX = datetime.now().strftime("%Y%m%d_%H%M%S")

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================
def load_csv(name: str) -> pd.DataFrame:
    path = DATA_DIR / name
    if not path.exists():
        raise FileNotFoundError(f"{path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    df = pd.read_csv(path)
    print(f"âœ… {name}: {len(df):,} ä»¶, åˆ—: {list(df.columns)}")
    return df

def standardize_date_column(df: pd.DataFrame, date_col: str) -> pd.DataFrame:
    df = df.copy()
    if date_col not in df.columns:
        return df
    df["date"] = pd.to_datetime(df[date_col], errors="coerce")
    return df.dropna(subset=["date"])

def normalize_gender(val):
    if pd.isna(val):
        return "ä¸æ˜"
    s = str(val).strip()
    if s in ["ç”·", "ç”·æ€§", "M", "male", "Male"]:
        return "ç”·æ€§"
    if s in ["å¥³", "å¥³æ€§", "F", "female", "Female"]:
        return "å¥³æ€§"
    return s or "ä¸æ˜"

def normalize_qual_sign(val: str) -> str:
    s = str(val).replace("ï¼‹", "+").replace("ï¼", "-").strip()
    if s in ["é™°æ€§", "negative", "neg", "(-)"]:
        return "NEG"
    if s in ["é™½æ€§", "positive", "(+)"]:
        return "POS1"
    if s in ["++", "(++)"]:
        return "POS2"
    if s in ["+++", "(+++)"]:
        return "POS3"
    if s in ["+", "+ ", " +"]:
        return "POS1"
    if s in ["-", "- ", " -"]:
        return "NEG"
    if s in ["Â±", "+-"]:
        return "BORDERLINE"
    return s

def preprocess_inspection_value(val):
    """å®šé‡â†’floatåŒ–ã€å®šæ€§â†’ã‚³ãƒ¼ãƒ‰åŒ–"""
    if pd.isna(val):
        return np.nan
    if isinstance(val, (int, float)):
        return float(val)
    s = str(val).strip()
    m = re.search(r"([-+]?\d*\.?\d+)", s)
    if m:
        try:
            return float(m.group(1))
        except Exception:
            pass
    return normalize_qual_sign(s)

def add_inspection_type(series: pd.Series) -> pd.Series:
    return series.apply(lambda v: "quantitative" if isinstance(v, float) else ("qualitative" if pd.notna(v) else "unknown"))

def cap_categories(series: pd.Series, top_k: int, other_token: str) -> pd.Series:
    vc = series.fillna("").astype(str).value_counts()
    keep = set(vc.head(top_k).index)
    return series.fillna("").astype(str).apply(lambda x: x if x in keep and x != "" else other_token)

# =========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================
def main():
    print(f"ğŸ“¦ SDV CTGAN ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | {datetime.now():%Y-%m-%d %H:%M:%S}")
    print(f"ğŸ“ å…¥åŠ›: {DATA_DIR.resolve()}")
    print(f"ğŸ’¾ å‡ºåŠ›: {OUTPUT_DIR.resolve()}")
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")

    # --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
    gender_df     = load_csv("gender.csv")
    disease_df    = load_csv("disease.csv")
    inspection_df = load_csv("inspection.csv")
    drug_df       = load_csv("drug.csv")
    emr_df        = load_csv("emr.csv")

    # --- æ—¥ä»˜åˆ—ã®æ­£è¦åŒ– ---
    disease_df    = standardize_date_column(disease_df,    "disease_date")
    inspection_df = standardize_date_column(inspection_df, "inspection_date")
    drug_df       = standardize_date_column(drug_df,       "key_date")
    emr_df        = standardize_date_column(emr_df,        "emr_date")

    # --- å„ç¨®æ­£è¦åŒ– ---
    gender_df["gender"] = gender_df["gender"].map(normalize_gender)
    inspection_df["inspection_value"] = inspection_df["inspection_value"].map(preprocess_inspection_value)
    inspection_df["inspection_type"]  = add_inspection_type(inspection_df["inspection_value"])

    # --- çµ±åˆ ---
    print("ğŸ§© ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
    merged = (
        disease_df.merge(drug_df, on=["patient_id", "date"], how="outer", suffixes=("_disease", "_drug"))
        .merge(inspection_df, on=["patient_id", "date"], how="outer")
        .merge(emr_df, on=["patient_id", "date"], how="outer")
        .merge(gender_df, on="patient_id", how="left")
    )
    merged = merged.sort_values(["patient_id", "date"]).reset_index(drop=True)
    print(f"âœ… çµ±åˆã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(merged):,}")

    # --- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ ---
    train = merged[[
        "patient_id", "date", "gender",
        "disease_name", "drug_name",
        "inspection_name", "inspection_value", "inspection_type"
    ]].copy()

    train["days_since_first"] = train.groupby("patient_id")["date"].transform(lambda x: (x - x.min()).dt.days)
    train["month"] = train["date"].dt.month
    train = train.drop(columns=["date", "patient_id"])

    # --- ã‚«ãƒ†ã‚´ãƒªåœ§ç¸® ---
    train["disease_name"]    = cap_categories(train["disease_name"],    TOPK_DISEASE,    "OTHER_DISEASE")
    train["drug_name"]       = cap_categories(train["drug_name"],       TOPK_DRUG,       "OTHER_DRUG")
    train["inspection_name"] = cap_categories(train["inspection_name"], TOPK_INSPECTION, "OTHER_INSPECTION")
    train["inspection_value"] = cap_categories(train["inspection_value"], TOPK_VALUE, "OTHER_VALUE")

    train["gender"] = train["gender"].fillna("ä¸æ˜")
    train["inspection_type"] = train["inspection_type"].fillna("unknown")

    train_out = OUTPUT_DIR / f"event_training_data_{SAVE_PREFIX}.csv"
    train.to_csv(train_out, index=False, encoding="utf-8-sig")
    print(f"ğŸ’¾ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {train_out}")

    # --- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ ---
    print("ğŸ§  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­...")
    metadata = SingleTableMetadata()
    metadata.detect_from_dataframe(train)

    metadata.update_column("inspection_value", sdtype="categorical")
    metadata.update_column("inspection_type",  sdtype="categorical")
    metadata.update_column("gender",           sdtype="categorical")
    metadata.update_column("disease_name",     sdtype="categorical")
    metadata.update_column("drug_name",        sdtype="categorical")
    metadata.update_column("inspection_name",  sdtype="categorical")
    metadata.update_column("month",            sdtype="categorical")
    metadata.update_column("days_since_first", sdtype="numerical")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ¤– CTGAN å­¦ç¿’é–‹å§‹ï¼ˆEPOCHS={EPOCHS}, device={device}ï¼‰...")
    ctgan = CTGANSynthesizer(
        metadata,
        epochs=EPOCHS,
        cuda=torch.cuda.is_available()
    )

    # --- å­¦ç¿’å®Ÿè¡Œ ---
    ctgan.fit(train)
    print("âœ… å­¦ç¿’å®Œäº†")

    # --- ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ---
    model_path = OUTPUT_DIR / f"ctgan_model_{SAVE_PREFIX}.pkl"
    ctgan.save(str(model_path))
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")

    # --- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ ---
    meta_json_path = OUTPUT_DIR / f"ctgan_metadata_{SAVE_PREFIX}.json"
    try:
        metadata.save_to_json(str(meta_json_path))
        print(f"ğŸ’¾ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {meta_json_path}")
    except Exception as e:
        print(f"âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ™‚ã®è­¦å‘Š: {e}")

    # --- ç–‘ä¼¼ã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆ ---
    print(f"ğŸ§¬ ç–‘ä¼¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ {SAMPLE_N} ä»¶ç”Ÿæˆä¸­...")
    synth = ctgan.sample(SAMPLE_N)
    synth_out = OUTPUT_DIR / f"synthetic_events_{SAVE_PREFIX}.csv"
    synth.to_csv(synth_out, index=False, encoding="utf-8-sig")

    print("\n=== ç”Ÿæˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ===")
    print(synth.head(min(10, SAMPLE_N)))

    print(f"\nğŸ’¾ ç–‘ä¼¼ã‚¤ãƒ™ãƒ³ãƒˆå‡ºåŠ›: {synth_out}")
    print("ğŸ‰ Step 03 å®Œäº† â€” å®šæ€§/å®šé‡å¯¾å¿œãƒ»Windowså®‰å®šåŒ–æ¸ˆã¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚")


if __name__ == "__main__":
    main()
